
# ğŸ§© Synthetic-Persona-Chat (SPC) Dataset

The **Synthetic-Persona-Chat (SPC)** dataset is a large-scale, high-quality **persona-based conversational dataset** designed to train and evaluate dialogue models that simulate consistent, human-like personalities.

This dataset was generated by **Google Research** using a *Generatorâ€“Critic architecture* involving multiple large language models to ensure diverse, coherent, and faithful conversations between persona-driven agents.

---

## ğŸ“š Overview

### âœ³ï¸ Purpose

SPC provides a rich source of conversational data with **explicit personas** for each speaker, enabling research into:

* Persona-grounded dialogue generation
* Long-term consistency and coherence in conversation
* Personality-conditioned responses
* Evaluation of LLM conversational empathy and engagement

---

## ğŸ“‚ Dataset Structure

The dataset consists of two main parts:

1. **Extended Persona-Chat Data**

   * 4,723 personas
   * 10,906 conversations
   * Uses the same train/validation/test splits as the original Persona-Chat dataset

2. **New Synthetic Personas and Conversations**

   * 5,648 synthetic personas
   * 11,001 conversations

Each conversation is formatted as a JSON object:

```json
{
  "User 1 Persona": [
    "I enjoy painting during the weekends.",
    "I live in a small town near the mountains."
  ],
  "User 2 Persona": [
    "I love hiking and spending time outdoors.",
    "I am currently training for a marathon."
  ],
  "Conversation": [
    {"speaker": "User 1", "text": "Hey! Do you go hiking often?"},
    {"speaker": "User 2", "text": "Pretty much every week. The trails here are beautiful!"}
  ]
}
```

---

## ğŸ§  Key Features

| Feature           | Description                                                  |
| ----------------- | ------------------------------------------------------------ |
| **Conversations** | 20,000 total multi-turn dialogues                            |
| **Personas**      | Over 10,000 unique persona profiles                          |
| **Format**        | JSON (structured conversations)                              |
| **Language**      | English                                                      |
| **Use Case**      | Persona-based chatbots, LLM fine-tuning, dialogue evaluation |
| **License**       | CC-BY-4.0                                                    |

---

## ğŸš€ Usage Example

### Load via Hugging Face `datasets` Library

```python
from datasets import load_dataset

# Load the dataset
dataset = load_dataset("google/Synthetic-Persona-Chat")

# Access first conversation
sample = dataset["train"][0]

print("User 1 Persona:", sample["User 1 Persona"])
print("User 2 Persona:", sample["User 2 Persona"])
print("Conversation sample:", sample["Conversation"][:2])
```

### Example Output

```
User 1 Persona: ['I enjoy painting during the weekends.', 'I live in a small town near the mountains.']
User 2 Persona: ['I love hiking and spending time outdoors.', 'I am currently training for a marathon.']
Conversation sample:
[{'speaker': 'User 1', 'text': 'Hey! Do you go hiking often?'},
 {'speaker': 'User 2', 'text': 'Pretty much every week. The trails here are beautiful!'}]
```

---

## ğŸ§© Applications

* **LLM Fine-tuning** â€” Train dialogue models that maintain consistent personalities
* **Evaluation** â€” Assess coherence, empathy, and engagement of conversational agents
* **Persona Modeling** â€” Explore how personality traits influence dialogue tone and flow
* **Controlled Generation** â€” Enable controllable chatbots that can take on user-specified roles

---

## ğŸ”¬ Research Background

The dataset was introduced in the paper:

> *Faithful Persona-based Conversational Dataset Generation with Large Language Models*
> **Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, Hakim Sidahmed** (2023)

The authors propose a **Generatorâ€“Critic Framework**:

* **Generator:** An LLM prompted to output conversations based on persona pairs
* **Critic:** A mixture of expert LLMs that evaluate and select the best outputs
* This iterative process improved conversation quality across three refinement stages, reducing â€œlosing rateâ€ in Turing tests from **17.2% â†’ 8.8%**

---

## ğŸ“Š Dataset Statistics

|                       Metric |                     Value |
| ---------------------------: | ------------------------: |
|                     Personas |                    10,371 |
|                Conversations |                    21,907 |
|  Average Conversation Length |                 8.4 turns |
| Average Persona Descriptions |              4â€“6 per user |
|                     Language |                   English |
|                        Split | Train / Validation / Test |

---

## ğŸ“– Citation

If you use this dataset, please cite the original work:

```bibtex
@misc{jandaghi2023faithful,
      title={Faithful Persona-based Conversational Dataset Generation with Large Language Models}, 
      author={Pegah Jandaghi and XiangHai Sheng and Xinyi Bai and Jay Pujara and Hakim Sidahmed},
      year={2023},
      eprint={2312.10007},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

---

## ğŸ”— References

* **Repository:** [https://github.com/google-research-datasets/Synthetic-Persona-Chat](https://github.com/google-research-datasets/Synthetic-Persona-Chat)
* **Paper:** [https://arxiv.org/abs/2312.10007](https://arxiv.org/abs/2312.10007)
* **Base Dataset:** [Persona-Chat (Zhang et al., 2018)](https://arxiv.org/abs/1801.07243)

---

## ğŸ“œ License

This dataset is released under the **Creative Commons Attribution 4.0 International (CC BY 4.0)** license.
You are free to share and adapt the material, provided appropriate credit is given.

---

